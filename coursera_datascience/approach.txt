Titanic

http://www.kaggle.com/c/titanic-gettingStarted/

The code/work in this directory is part of the Kaggle assignment for the Data Science course. Taking
a pragmatic approach, the code/work here is not aiming for the best possible predictability, but
doing what the assignment requires. Essentially, this boils down to the following:

1. Take an initial stab at the problem, and see what works.
2. Improve on it.

First cut:
Keep it simple. Help establish a baseline

Improvements:
Random Forest


Tasks:

Programming:
* Have a decision tree implementation
    - AI::DecisionTree. Done
* Sample data for Bootstrap, and for use with Random Forest
    - Use Statistics::R and sample through R. much simpler to: a) m samples out of n, b) with and
        without replacement, c) probability vector support in case we want to do boosting

* Calculate a measure of "information exchange", class purity, or entropy.
    - Gini Coefficient is simple. Do this.

* Evaluate the trained decision tree with test data.
    - error rate?



